# Statistics One, 2013, Lab 8

# Lab goals
#   Conduct group comparisons
#     Dependent t-tests
#     Independent t-tests
#     Analysis of Variance (ANOVA)

# Example
#  Working memory training experiment (N = 120)
#  The dependent variable (DV) is number of items answered correctly on an intelligence test
#  There are three independent variables:
#    Time (2 levels): pre and post training
#    Training (2 levels): training (1) and control (0) (n.training = 80, n.control = 40)
#    Training sessions (4 levels): 8, 12, 17, 19 (for each, n = 20)

# Check your working directory
# getwd()
# If necessary, set your working directory
# setwd("Users/aconway/Dropbox/STATS1-V2.0/Labs")

# If necessary, install packages
# install.packages("psych")
# install.packages("car")

# Load packages
library(psych)
library(car)
library(lsr)
library(ggplot2)
library(reshape)

#First, copy it in Excel. Then to read data:
> x <- read.table(file = "clipboard", sep = "\t", header=TRUE)
> x

# Read data into a dataframe called wm
wm = read.table("Stats1.13.Lab.08.txt", header = T)

# If you want to view the data
# View(wm)
edit(wm)

# Summary statistics by all groups (control, 8 sessions, 12 sessions, 17 sessions, 19 sessions)
describeBy(wm, wm$cond)

# Create two subsets of data: One for the control group and another for the training groups
wm.c = subset(wm, wm$train == "0")
wm.t = subset(wm, wm$train == "1")
freqs.A = subset(freqs, freqs$Produtividade == "Alta")
freqs.B = subset(freqs, freqs$Produtividade == "Baixa")
freqs.S = subset(freqs, freqs$Est2 == "Seca")
freqs.C = subset(freqs, freqs$Est2 == "Chuvosa")
freqs.se = subset(freqs, freqs$Est3 == "Seca")
freqs.ch = subset(freqs, freqs$Est3 == "Chuvosa")
freqs.um = subset(freqs, freqs$Est3 == "Umida")

# Save summary statistics in tables to illustrate calculation of effect size
wm.c.out = describe(wm.c)
wm.c.out
wm.t.out = describe(wm.t)
wm.t.out

# Dependent t-tests

# First, compare pre and post scores in the control group
t.test(wm.c$post, wm.c$pre, paired = T)

# Next, compare pre and post scores in the training groups
t.test(wm.t$post, wm.t$pre, paired = T)

# Cohen's d for dependent t-tests
# d = Mean of difference scores / Standard deviation of difference scores

d.c = (wm.c.out[4,3]) / (wm.c.out[4,4])
d.c
#or
cohensD(wm.c$post, wm.c$pre, method="paired")

d.t = (wm.t.out[4,3]) / (wm.t.out[4,4])
d.t
#or
cohensD(wm.t$post, wm.t$pre, method="paired")
 
# Boxplot
long.wm <- melt(wm, id=c("cond", "train", "gain"))

ggplot(long.wm, aes(x=cond, y=value, color=variable)) + 
  geom_boxplot() +
  guides(fill=FALSE) 
  
# Independent t-test

# Compare the gain scores in the dry and rainy season groups 
t.test(wm$gain ~ wm$train, var.equal = T)
t.test(freqs.S$LOC, freqs.C$LOC, var.equal = T)

# Cohen's d for independent t-tests
# d = (M1 - M2) / Pooled Standard Deviation

pooled.sd = (79/118 * wm.t.out[4,4]) + (39/118 * wm.c.out[4,4])

d.ct = (wm.t.out[4,3] - wm.c.out[4,3]) / pooled.sd
d.ct
# or
cohensD(wm$gain ~ wm$train, method="pooled")

# Boxplot
ggplot(wm, aes(x=cond, y=gain, fill=cond)) + 
  geom_boxplot() +
  guides(fill=FALSE)
  
# To compare the gain scores across all groups, use ANOVA
# First, check the homogeneity of variance assumption
leveneTest(wm.t$gain, wm.t$cond, center="mean")
leveneTest(wm.t$gain, wm.t$cond)

aov.model = aov(wm.t$gain ~ wm.t$cond)
summary(aov.model)

# Save results in a table to illustrate calculation of effect size
aov.table = summary(aov.model)

# Effect size for ANOVA
ss = aov.table[[1]]$"Sum Sq"
eta.sq = ss[1] / (ss[1] + ss[2])
eta.sq
#or
etaSquared(aov.model, anova=T)

# Conduct post-hoc tests to evaluate all pairwise comparisons
TukeyHSD(aov.model)


# One-way ANOVA # testing Value against Group

#Before running a one-way ANOVA test, you need to test if the homogeneity of variances assumption holds. 
#we use Barlett's test here, where p value is over 0.05, the null hypothesis still holds.
bartlett.test(Value ~ Group,data)
bartlett.test(freqs$LOC ~ freqs$Est3, freqs)

##Ex. data:
Group <- factor(c("A","A","A","A","A","B","B","B","B","B","C","C","C","C","C"))
Value <- c(1,2,4,1,1,2,2,3,3,4,4,2,3,4,4,3,4,5,3,5,5,3,4,6)
aov <- aov(Value ~ Group, data)
summary(aov)

> ov <- aov(freqs$LOC ~ freqs$Est3, freqs)
> summary(ov)  # mostra o resultado

## look at the results for the individual levels of the factors.
> model.tables(ov, type='effects') # how much effect every one had
> model.tables(ov, type='means') # modeled means per group and the overall mean

## How to look at individual differences in data
> TukeyHSD(ov)  or  
> TukeyHSD(aov(freqs$LOC ~ freqs$Est3, freqs)) # that gives:
 * difference between the means; 
 * lower and upper level of the 95 percent confidence interval around that mean difference.
 * p-value that tells you whether this difference is significantly different from zero.

# Nonparametric multiple comparison #

mar <- c(9.7,9.8,9.6,9.5,NA)   # only 4 values
jun <- c(4.2,6.7,5.8,7.5,4.4)
sep <- c(9.6,9.4,8.9,9.4,9.5)
month <- gl(3,5,labels=c("Mar","Jun","Sep"))
injuries <- c(mar,jun,sep)
> pairwise.wilcox.test(injuries,month)

estacao3 <- c("freqs.se","freqs.ch","freqs.um")
pairwise.wilcox.test(freqs$LOC,estacao3)
